#!/usr/bin/env python
#
# Copyright (C) STMicroelectronics Ltd. 2012
#
# This file is part of ATOS.
#
# ATOS is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License v2.0
# as published by the Free Software Foundation
#
# ATOS is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# v2.0 along with ATOS. If not, see <http://www.gnu.org/licenses/>.
#
# Usage: get usage with atos-lib -h
#

VERSION="@VERSION@"

import os, sys, re, math, itertools, time, fcntl, json
import cPickle as pickle
from pprint import pprint, pformat


# ####################################################################


class atos_db():

    keys = ['target', 'environment', 'compiler', 'dataset', 'session']

    required_keys = ['target', 'environment', 'compiler', 'session']

    required_fields = ['target', 'variant', 'size', 'time']

    def __init__(self): raise NotImplementedError

    # add new result records
    #   ex: add_results([
    #           {'target': 'x', 'variant': 'REF', 'time': 14.0, 'size': 10}])
    def add_results(self, entries): raise NotImplementedError

    # return list of records
    #   [ {'target': 'x', 'variant': 'REF', 'time' : ...}, {...}, ...]
    #   query can be a dict or a jsonlib search string
    #   ex: get({}) : all records
    #   ex: get({'target' : 'x', 'variant' : 'REF'})
    #   ex: get('$[?(@.target="x" && @.variant="REF")]'
    def get_results(self, query=None): raise NotImplementedError

    #
    @staticmethod
    def db(atos_configuration):
        # results.pkl  loadtime:  3.50s  filesize: 229M
        db_file = os.path.join(atos_configuration, 'results.pkl')
        if os.path.exists(db_file): return atos_db_pickle(db_file)
        # results.json loadtime: 27.63s  filesize: 217M
        db_file = os.path.join(atos_configuration, 'results.json')
        if os.path.exists(db_file): return atos_db_json(db_file)
        # results.db   loadtime:  5.70s  filesize: 579M
        db_file = os.path.join(atos_configuration, 'results.db')
        if os.path.exists(db_file): return atos_db_file(db_file)


# ####################################################################


class atos_db_file(atos_db):

    def __init__(self, db_file):
        self.db_file = db_file
        self.results = []
        self._create()
        self._read_results()

    def get_results(self, query=None):
        return results_filter(self.results, query)

    def add_results(self, entries):
        self.results.extend(entries)
        self._write_entries(entries)

    def _write_entries(self, entries):
        entries_str = ''
        for entry in entries:
            # last line must be one of the required field (time or size)
            entry_keys = list(entry.keys())
            entry_keys.remove('time'); entry_keys += ['time']
            for key in entry_keys:
                entries_str += 'ATOS: %s: %s: %s: %s\n' % (
                    entry['target'], entry['variant'], key, entry[key])
        with open_locked(self.db_file, 'a') as db_file:
            db_file.write(entries_str)

    def _read_results(self):
        if not os.path.exists(self.db_file): return
        curdict, size, time = {}, None, None
        for line in open_locked(self.db_file):
            words = line.split(':', 4)
            if len(words) < 4: continue
            # ATOS: target: variant_id: key: value
            target, variant, key, value = [
                w.strip() for w in words[1:]]
            curdict[key] = value
            if key == 'size': size = value
            if key == 'time': time = value
            if not (size and time): continue
            curdict['target'] = target
            curdict['variant'] = variant
            self.results += [result_entry(curdict)]
            curdict, size, time = {}, None, None

    def _create(self):
        if os.path.exists(self.db_file): return
        open(self.db_file, 'w').write('')


# ####################################################################


class atos_db_json(atos_db):

    def __init__(self, db_file):
        self.db_file = db_file
        self.results = []
        self._create()
        self._read_results()

    def get_results(self, query=None):
        return results_filter(self.results, query)

    def add_results(self, entries):
        with open_locked(self.db_file, 'r+') as db_file:
            self.results = json.load(db_file)
            db_file.seek(0); db_file.truncate()
            self.results.extend(entries)
            json.dump(self.results, db_file)

    def _read_results(self):
        self.results = json.load(open_locked(self.db_file))

    def _create(self):
        if os.path.exists(self.db_file): return
        json.dump([], open(self.db_file, 'w'))


# ####################################################################


class atos_db_pickle(atos_db):

    def __init__(self, db_file):
        self.db_file = db_file
        self.results = []
        self._create()
        self._read_results()

    def get_results(self, query=None):
        return results_filter(self.results, query)

    def add_results(self, entries):
        with open_locked(self.db_file, 'r+') as db_file:
            self.results = pickle.load(db_file)
            db_file.seek(0); db_file.truncate()
            self.results.extend(entries)
            pickle.dump(self.results, db_file, -1)

    def _read_results(self):
        self.results = pickle.load(open_locked(self.db_file))

    def _create(self):
        if os.path.exists(self.db_file): return
        pickle.dump([], open(self.db_file, 'w'), -1)


# ####################################################################


class atos_client_results():

    class result():

        def __init__(self, result):
            for (key, val) in result.items():
                exec 'self.%s = type(%s)("%s")' % (key, 'val', val)

        def __repr__(self):
            return '<%s:%s>' % (self.target, self.variant)

        def __str__(self):
            return str(self.dict())

        def dict(self):
            return dict(
                filter(lambda x: x[0][0] != '_', self.__dict__.items()))

        def speedup(self, ref):
            self.speedup = ((ref.time / self.time) - 1.0)
            self.sizered = (1.0 - (float(self.size) / float(ref.size)))
            return self.speedup, self.sizered

        @staticmethod
        def merge_multiple_runs(results):
            newobj = atos_client_results.result(results[0].__dict__)
            # average of execution times
            newobj.time = average(map(lambda x: x.time, results))
            newobj._results = results
            return newobj

        @staticmethod
        def merge_targets(group_name, results):
            newobj = atos_client_results.result(results[0].__dict__)
            # geometric mean of execution times, sum of binary sizes
            newobj.time = geometric_mean(map(lambda x: x.time, results))
            newobj.size = sum(map(lambda x: x.size, results))
            newobj.target = group_name
            # last group results - last result of each target
            newobj._last = atos_client_results.result(newobj.__dict__)
            newobj._last.time = geometric_mean(
                map(lambda x: x._results[-1].time, results))
            newobj._results = results
            return newobj

    def __init__(self, atos_db, group_targets, query={}, group_name=None):
        self.db = atos_db
        if not group_targets:
            group_targets = list(set(self.db.get_results('$[*].target')))
        group_name = group_name or '+'.join(group_targets)
        self.values = (group_targets, query, group_name)
        # results: { variant : [ result_obj ] }
        self.results = self._get_group_results(group_targets, group_name, query)

    def compute_frontier(self):
        maybe_on_frontier, mustbe_on_frontier = self.results.values(), set()
        for (variant, c1) in self.results.items():
            on_frontier = True
            maybe_on_frontier.remove(c1)
            for c2 in itertools.chain(mustbe_on_frontier, maybe_on_frontier):
                if c2.time == c1.time and c2.size == c1.size:
                    pass
                elif c2.time <= c1.time and c2.size <= c1.size:
                    on_frontier = False
                    break
            if on_frontier: mustbe_on_frontier.add(c1)
            c1.on_frontier = on_frontier
        self.frontier = mustbe_on_frontier
        return mustbe_on_frontier

    def compute_speedups(self, ref_variant='REF'):
        assert ref_variant in self.results.keys()
        for (variant, result) in self.results.items():
            result.speedup(self.results[ref_variant])
        return self.results.values()

    def get_last_result(self, variant):
        assert variant in self.results.keys()
        return self.results[variant]._last

    def get_results(self, only_frontier=False, objects=False):
        if only_frontier:
            if not hasattr(self, 'frontier'):
                self.compute_frontier()
            results = self.frontier
        else: results = self.results.values()
        if not objects:
            results = map(lambda x: x.dict(), results)
        return results

    def _get_group_results(self, group_targets, group_name, query):
        # get results for each target of the group
        results, target_results = {}, {}
        for target in group_targets:
            target_results[target] = self._get_target_results(target, query)
        # find list of variants common to all targets
        common_variants = set(target_results[group_targets[0]].keys())
        for target in group_targets:
            common_variants = common_variants.intersection(
                target_results[target].keys())
        # compute group results
        for variant in common_variants:
            results[variant] = atos_client_results.result.merge_targets(
                group_name,
                map(lambda x: target_results[x][variant], group_targets))
        return results

    def _get_target_results(self, target, query):
        full_query = dict.fromkeys(atos_db.keys, '.*')
        full_query.update(query)
        full_query.update({'target' : target})
        # query results for given target
        reslist = self.db.get_results(full_query)
        # create results dict
        results = {} # { variant : [ result_obj ] }
        for res in reslist:
            results.setdefault(res['variant'], []).append(
                atos_client_results.result(res))
        # merge multiple runs (average execution times)
        for variant in results.keys():
            results[variant] = atos_client_results.result.merge_multiple_runs(
                results[variant])
        return results


# ####################################################################


class atos_client_db():

    def __init__(self, atos_db):
        self.db = atos_db

    def query(self, query={}, replacement={}):
        return atos_client_db.db_query(self.db, query, replacement)

    def add_result(self, entry):
        required_fields = set(atos_db.required_fields)
        if not set(entry.keys()).issuperset(required_fields):
            return False, list(required_fields.difference(set(entry.keys())))
        entry = result_entry(entry)
        self.db.add_results([entry])
        return True, entry

    @staticmethod
    def db_load(inf):
        return json.load(inf)

    @staticmethod
    def db_dump(results, outf):
        pprint_list(results, outf)
        return True, len(results)

    @staticmethod
    def db_query(db, query={}, replacement={}):
        results = db.get_results(query)
        if replacement:
            for result in results:
                result.update(replacement)
        return results

    @staticmethod
    def db_transfer(db, results, force):
        required_keys, missing_keys = set(atos_db.required_keys), set()
        if not force:
            for result in results:
                if not set(result.keys()).issuperset(required_keys):
                    missing_keys |= required_keys.difference(set(result.keys()))
        if missing_keys: return False, list(missing_keys)
        db.add_results(results)
        return True, len(results)


# ####################################################################


def timer(func):
    def wrapper(*args, **kwargs):
        t0 = time.time()
        res = func(*args, **kwargs)
        t1 = time.time()
        print 'timer: %r %.2fs' % (func.__name__, t1 - t0)
        return res
    return wrapper

def average(l):
    return sum(l) / len(l)

def geometric_mean(l):
    return (10 ** (sum(map(math.log10, l)) / len(l)))

def standard_deviation(l):
    avg = average(l)
    variance = average([((x - avg) ** 2) for x in l])
    return math.sqrt(variance)

def variation_coefficient(l):
    return (standard_deviation(l) / average(l))


def strtodict(s):
    # 'aa:xx,bb:yy' -> {'aa':'xx','bb':'yy'}
    d = {}
    if s == '': return d
    for kv in s.split(','):
        k, v = kv.split(':')
        d[k] = v
    return d

def strtoquery(s):
    if not s:
        return {}
    if s[0].isalpha():
        return strtodict(s)
    return s

def strtolist(s):
    return s.split(',')

def results_filter(results, query):
    if not query: return results
    if isinstance(query, str):
        import jsonlib
        return jsonlib.search(results, query)
    return (filter(lambda x: all(
                map(lambda (k,v): re.match('^%s$' % v, x.get(k, '')),
                    query.items())), results))

def result_entry(d):
    try:
        d['time'] = float(d['time'])
        d['size'] = int(d['size'])
    except:
        d['time'] = d['size'] = 'FAILURE'
    return d

def open_locked(filename, mode='r'):
    while True:
        outf = open(filename, mode)
        try:
            fcntl.flock(outf, fcntl.LOCK_EX | fcntl.LOCK_NB)
            return outf
        except: outf.close()
        time.sleep(1)

def pprint_list(list, out=None, text=False):
    out = out or sys.stdout
    if not list: print >>out, None; return
    if text:
        for x in list: print x
        return
    print >>out, '[',
    nb_elems = len(list)
    for i in range(nb_elems):
        print >>out, '%s%s%s' % (
            i>0 and '  ' or '',
            json.dumps(list[i]), ((i + 1) < nb_elems) and ',\n' or ''),
    print >>out, ']'

def info(msg):
    # do not print info on stdout (as it can be used for dump/load)
    # could be replaced by logging.info
    print >> sys.stderr, msg


# ####################################################################




if __name__ == '__main__':


    # ################################################################

    import optparse

    help_lines = [
        '',
        'Available actions:',
        '  create_db   create a new database',
        '  add_result  add result entry',
        '  push        export results to another database',
        '  pull        import results from another database',
        '  query       query results',
        '  speedups    list results',
        '',
        'type \'%s <action> -h\' for more help on a specific action.' % (
            os.path.basename(sys.argv[0])), '']

    parser = optparse.OptionParser(
        usage='%prog action [options]', version="%prog version " + VERSION)
    parser.format_epilog = lambda x: '\n'.join(help_lines)

    if len(sys.argv) < 2: parser.error('action expected')

    (opts, args) = parser.parse_args([sys.argv[1]])


    # ################################################################

    if args[0] == 'create_db':

        subparser = optparse.OptionParser(
            description = 'Create a new empty database',
            usage='%%prog %s [options]' % args[0])
        subparser.add_option('-C', dest='configuration_path',
                action='store', type='string', default='./atos-configurations',
                help='configuration path (default: ./atos-configurations)')
        subparser.add_option('-t', '--type', dest='type',
                action='store', type='choice', default='results_db',
                choices=['results_db', 'json', 'pickle'],
                help='database type '
                     '[results_db|json|pickle] (default: results_db)')
        subparser.add_option('--shared', dest='shared',
                action='store_true', default=False,
                help='create a shared database '
                             '(group has write permission) (default: False)')
        subparser.epilog = 'Example: create_db -C. -tjson'
        (opts, args) = subparser.parse_args(sys.argv[1:])

        if not os.path.exists(opts.configuration_path):
            os.makedirs(opts.configuration_path)
        if opts.type == 'results_db':
            db_file = os.path.join(opts.configuration_path, 'results.db')
            db = atos_db_file(db_file)
        elif opts.type == 'json':
            db_file = os.path.join(opts.configuration_path, 'results.json')
            db = atos_db_json(db_file)
        elif opts.type == 'pickle':
            db_file = os.path.join(opts.configuration_path, 'results.pkl')
            db = atos_db_pickle(db_file)
        else: assert 0
        if opts.shared: os.chmod(db_file, 0660)
        info('created new database in "%s"' % db_file)


    # ################################################################

    elif args[0] == 'query':

        subparser = optparse.OptionParser(
            description = 'Query database results',
            usage='%%prog %s [options]' % args[0])
        subparser.add_option('-C', dest='configuration_path',
                action='store', type='string', default='./atos-configurations',
                help='configuration path (default: ./atos-configurations)')
        subparser.add_option('-q', '--query', dest='query',
                action='store', type='string', default='',
                help='results query values (default: None)')
        subparser.add_option('-t', '--text', dest='text',
                action='store_true', default=False,
                help='text output format (default: json)')
        subparser.epilog = 'Examples: \n' \
            '    query -q "variant:REF,compiler:gcc-4.*"\n' \
            '    query -q "$[?(@.target="aaa" && @.variant="REF")]"\n' \
            '    query -q "$[?(@.target="aaa")].size"\n'
        subparser.format_epilog = lambda x: subparser.epilog
        (opts, args) = subparser.parse_args(sys.argv[1:])

        if opts.configuration_path == '-':
            results = results_filter(
                atos_client_db.db_load(sys.stdin), strtoquery(opts.query))

        else:
            client = atos_client_db(atos_db.db(opts.configuration_path))
            results = client.query(strtoquery(opts.query))

        pprint_list(results, text=opts.text)


    # ################################################################

    elif args[0] == 'add_result':

        subparser = optparse.OptionParser(
            description = 'Add result to database',
            usage='%%prog %s [options]' % args[0])
        subparser.add_option('-C', dest='configuration_path',
                action='store', type='string', default='./atos-configurations',
                help='configuration path (default: ./atos-configurations)')
        subparser.add_option('-r', '--result', dest='result',
                action='store', type='string', default='',
                help='results values (default: None)')
        subparser.epilog = 'Example: addres -r"target:X,compiler:gcc,time:12"'
        (opts, args) = subparser.parse_args(sys.argv[1:])

        client = atos_client_db(atos_db.db(opts.configuration_path))

        status, output = client.add_result(strtodict(opts.result))

        if status:
            info('new result entry: %s' % pformat(output))
        else:
            info('missing fields: %s' % str(output))


    # ################################################################

    elif args[0] == 'push':

        subparser = optparse.OptionParser(
            description = 'Export results to another database',
            usage='%%prog %s [options]' % args[0])
        subparser.add_option('-C', '--C1', dest='configuration_path',
                action='store', type='string', default='./atos-configurations',
                help='configuration path (default: ./atos-configurations)')
        subparser.add_option('-R', '--C2', dest='remote_configuration_path',
                action='store', type='string', default=None,
                help='remote configuration path (default: None)')
        subparser.add_option('-q', '--query', dest='query',
                action='store', type='string', default='',
                help='query for exported results (default: None)')
        subparser.add_option('-r', '--repl', dest='replacement',
                action='store', type='string', default='',
                help='values replacement (default: None)')
        subparser.add_option('-f', '--force', dest='force',
                action='store_true', default=False,
                help='ignore missing keys (default: False)')
        subparser.epilog = 'Example: ' \
            'push -q"compiler:gcc,variant=OPT.*" -renvironment:u8500'
        (opts, args) = subparser.parse_args(sys.argv[1:])
        if not opts.remote_configuration_path:
            subparser.error(
                'expected a remote configuration_path (set with -R option)')

        db = atos_db.db(opts.configuration_path)
        results = atos_client_db.db_query(
            db, strtoquery(opts.query), strtodict(opts.replacement))

        if opts.remote_configuration_path == '-':
            status, output = atos_client_db.db_dump(results, sys.stdout)
        else:
            other_db = atos_db.db(opts.remote_configuration_path)
            status, output = atos_client_db.db_transfer(
                other_db, results, opts.force)

        if status:
            info('exported %d results' % (output))
        else:
            info('missing fields: %s (use -f option to ignore)' % (str(output)))


    # ################################################################

    elif args[0] == 'pull':

        subparser = optparse.OptionParser(
            description = 'Import results from another database',
            usage='%%prog %s [options]' % args[0])
        subparser.add_option('-C', '--C1', dest='configuration_path',
                action='store', type='string', default='./atos-configurations',
                help='configuration path (default: ./atos-configurations)')
        subparser.add_option('-R', '--C2', dest='remote_configuration_path',
                action='store', type='string', default=None,
                help='remote configuration path (default: None)')
        subparser.add_option('-q', '--query', dest='query',
                action='store', type='string', default='',
                help='query for exported results (default: None)')
        subparser.add_option('-r', '--repl', dest='replacement',
                action='store', type='string', default='',
                help='values replacement (default: None)')
        subparser.add_option('-f', '--force', dest='force',
                action='store_true', default=False,
                help='ignore missing keys (default: False)')
        subparser.epilog = 'Example: ' \
            'pull -q"compiler:gcc,variant=OPT.*" -renvironment:u8500'
        (opts, args) = subparser.parse_args(sys.argv[1:])
        if not opts.remote_configuration_path:
            subparser.error(
                'expected a remote configuration_path (set with -R option)')

        db = atos_db.db(opts.configuration_path)

        if opts.remote_configuration_path == '-':
            results = atos_client_db.db_load(sys.stdin)
        else:
            other_db = atos_db.db(opts.remote_configuration_path)
            results = atos_client_db.db_query(
                other_db, strtoquery(opts.query), strtodict(opts.replacement))

        status, output = atos_client_db.db_transfer(db, results, opts.force)

        if status:
            info('imported %d results' % (output))
        else:
            info('missing fields: %s (use -f option to ignore)' % (str(output)))


    # ################################################################

    elif args[0] == 'speedups':

        subparser = optparse.OptionParser(
            description = 'Get results',
            usage='%%prog %s [options]' % args[0])
        subparser.add_option('-C', dest='configuration_path',
                action='store', type='string', default='./atos-configurations',
                help='configuration path (default: ./atos-configurations)')
        subparser.add_option('-t', '--targets', dest='targets',
                action='store', type='string', default='',
                help='target list (default: None)')
        subparser.add_option('-q', '--query', dest='query',
                action='store', type='string', default='',
                help='results query values (default: None)')
        subparser.add_option('-g', '--group_name', dest='group_name',
                action='store', type='string', default=None,
                help='target group name (default: None)')
        subparser.add_option('-r', '--refid', dest='ref',
                action='store', type='string', default='REF',
                help='reference variant id (default: None)')
        subparser.add_option('-f', '--frontier', dest='frontier',
                action='store_true', default=False,
                help='only print frontier points (default: False)')
        subparser.epilog = \
            'Example: speedups -C. -q"target:bzip2,compiler:gcc" -rREF -f'
        (opts, args) = subparser.parse_args(sys.argv[1:])

        client = atos_client_results(
            atos_db.db(opts.configuration_path),
            opts.targets and strtolist(opts.targets),
            strtoquery(opts.query), opts.group_name)

        if opts.ref: client.compute_speedups(opts.ref)

        pprint_list(client.get_results(opts.frontier))


    # ################################################################

    else:
        parser.error("unknown action '%s'" % args[0])



# ####################################################################
